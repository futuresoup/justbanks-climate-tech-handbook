{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ac31669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tiktoken\n",
    "import openai\n",
    "from openai.embeddings_utils import get_embedding\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "\n",
    "embedding_model = \"text-embedding-ada-002\"\n",
    "embedding_encoding = \"cl100k_base\"  # this the encoding for text-embedding-ada-002\n",
    "max_tokens = 8000  # the maximum for text-embedding-ada-002 is 8191"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6ba44d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic = pd.read_csv(\"data/file_info.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "468402cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding(topic:str):\n",
    "    #check the existence of the topic\n",
    "    input_datapath = f\"data/articles/{topic}.csv\"\n",
    "    if not os.path.exists(input_datapath):\n",
    "        print(\"Topic: \"+topic+\" does not exist.\" )\n",
    "        return \n",
    "\n",
    "    # load & inspect dataset\n",
    "    df = pd.read_csv(input_datapath,header=0, encoding=\"utf8\")\n",
    "    df.fillna(\"\", inplace=True)\n",
    "    df[\"HTFXS\"]=( \"Title: \" + df.Heading.str.strip() +\"; Subtitle:\"+ df.Subtitle.str.strip() + \"; Content: \" + df.First.str.strip()+df.Text.str.strip()+ \"; Source: \"+ df.Source.str.strip() )\n",
    "    df[\"HTF\"]=( \"Title: \" + df.Heading.str.strip() + \"; Subtitle:\"+ df.Subtitle.str.strip() + \"; Content: \" + df.First.str.strip())\n",
    "    df[\"embedding\"] = df.HTF.apply(lambda x: get_embedding(x, engine=embedding_model))\n",
    "    df.to_csv(f\"data/embedding/{topic}.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40a6e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_embedding(start: int, end: int, df):\n",
    "    df=df.iloc[start:end]\n",
    "    for index, row in df.iterrows():\n",
    "        make_embedding(row['Topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "668ae639",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_embedding(0,5,df_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e55fe0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prompts.yml') as f:\n",
    "    prompts = yaml.safe_load(f)\n",
    "\n",
    "with open('template.md') as f:\n",
    "    template = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f98bda51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search through the articles for a specific topic & Heading\n",
    "def search_article(df, problem, n=8):\n",
    "    problem_embedding = get_embedding(\n",
    "        problem,\n",
    "        engine=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    df[\"similarity\"] = df.embedding.apply(lambda x: cosine_similarity(x, problem_embedding))\n",
    "\n",
    "    results = (\n",
    "        df.sort_values(\"similarity\", ascending=False)\n",
    "        .head(n)\n",
    "    )\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e60f205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_message(\n",
    "    query: str,\n",
    "    df: pd.DataFrame) -> str:\n",
    "    \"\"\"Return a message for GPT, with relevant source texts pulled from a dataframe.\"\"\"\n",
    "    query=query\n",
    "    message = 'Use the below articles to answer the subsequent question.'\n",
    "    question = f\"\\n\\nQuestion: {query}\"\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        message += row['HTFXS']\n",
    "    \n",
    "    return message + question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4e7c10ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(\n",
    "    query: str,\n",
    "    df: pd.DataFrame) -> str:\n",
    "    \"\"\"Answers a query using GPT and a dataframe of relevant texts and embeddings.\"\"\"\n",
    "    message = query_message(query,df)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You answer questions.\"},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    #print(messages)\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ad8f4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solution(topic):\n",
    "    input_datapath=f\"data/embedding/{topic}.csv\"\n",
    "    if not os.path.exists(input_datapath):\n",
    "        print(\"Topic: \"+topic+\" does not exist.\" )\n",
    "        return \n",
    "    df=pd.read_csv(input_datapath,header=0, encoding=\"utf8\")\n",
    "    df[\"embedding\"] = df.embedding.apply(eval).apply(np.array)\n",
    "    \n",
    "    progress_results = search_article(df,prompts['Progress Made']['embed'].replace('{Topic}', topic), n=8)\n",
    "    progress_made=ask(prompts['Progress Made']['prompt'].replace('{Topic}', topic), progress_results)\n",
    "    \n",
    "    lessons_results = search_article(df,prompts['Lessons Learned']['embed'].replace('{Topic}', topic), n=8)\n",
    "    lessons_learned=ask(prompts['Lessons Learned']['prompt'].replace('{Topic}', topic), lessons_results)\n",
    "    \n",
    "    challenges_results = search_article(df,prompts['Challenges Ahead']['embed'].replace('{Topic}', topic), n=8)\n",
    "    challenges_ahead=ask(prompts['Challenges Ahead']['prompt'].replace('{Topic}',topic), challenges_results)\n",
    "    \n",
    "    bestpath_results = search_article(df,prompts['Best Path Forward']['embed'].replace('{Topic}', topic), n=8)\n",
    "    best_path_forward=ask(prompts['Best Path Forward']['prompt'].replace('{Topic}', topic), bestpath_results)\n",
    "    \n",
    "     # Populate the template with the generated content and image URL\n",
    "    output = template.format(\n",
    "        topic=topic,\n",
    "        progress_made=progress_made,\n",
    "        lessons_learned=lessons_learned,\n",
    "        challenges_ahead=challenges_ahead,\n",
    "        best_path_forward=best_path_forward,\n",
    "        image_url='',#may need adjustment\n",
    "        credit_url='' #may need adjustment\n",
    "    )\n",
    "\n",
    "    # Write output to file\n",
    "    with open(f\"output/{topic}.md\", 'w') as f:\n",
    "        f.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ee5c809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_solution(start, end, df):\n",
    "    df=df.iloc[start:end]\n",
    "    for index, row in df.iterrows():\n",
    "        solution(row['Topic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6bb0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_solution(0,3, df_topic)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eods-s22",
   "language": "python",
   "name": "eods-s22"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
